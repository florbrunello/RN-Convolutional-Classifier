{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abccb29d",
   "metadata": {},
   "source": [
    "# Entrenamiento de Autoencoder y guardado de parámetros\n",
    "\n",
    "En este notebook se entrena un autoencoder convolucional sobre FashionMNIST, se registran las pérdidas de entrenamiento y validación y se guardan los parámetros del modelo para luego ser reutilizados desde `train.ipynb` en una red clasificadora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53f9708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (0.24.1)\n",
      "Requirement already satisfied: torchaudio in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: torchviz in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (0.0.3)\n",
      "Requirement already satisfied: filelock in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: numpy in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torchvision) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: graphviz in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from torchviz) (0.21)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/usuario/Documentos/RedesNeuronales/TPFinal/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# 1) Instalación de librerías requeridas\n",
    "!pip3 install torch torchvision torchaudio torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3767bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Importar librerías necesarias\n",
    "# 1.1)\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1.3)\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "#from torchviz import make_dot\n",
    "\n",
    "# Configuración de dispositivo\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7934f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1)\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "root_data = \"MNIST_data/\"\n",
    "# Download and load the full training data\n",
    "full_dataset = datasets.FashionMNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "\n",
    "# Split the full dataset into train and validation sets of (almost) equal size\n",
    "train_size = len(full_dataset) // 2\n",
    "valid_size = len(full_dataset) - train_size\n",
    "train_set_orig_autoencoder, valid_set_orig_autoencoder = random_split(full_dataset, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b356e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2.2)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "figure = plt.figure()\n",
    "cols,rows = 3,3\n",
    "for i in range(1,cols*rows+1):\n",
    "    j = torch.randint(len(train_set_orig_autoencoder),size=(1,)).item() # Los números aleatorios tambien se pueden generar desde pytorch. Util para trabajar en la GPU.\n",
    "    image,label = train_set_orig_autoencoder[j]\n",
    "    figure.add_subplot(rows,cols,i)\n",
    "    #plt.title(labels_names[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image.squeeze(),cmap=\"Greys_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d22587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1)\n",
    "# Creamos una subclase de la clase Dataset que nos sirva para generar lotes de ejemplos que puedan usarse para entrenar un autoencoder\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset=dataset\n",
    "    # Redefinimos el método .__len__()\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    # Redefinimos el método .__getitem__()\n",
    "    def __getitem__(self,i):\n",
    "        image,label=self.dataset[i]\n",
    "        input  = image\n",
    "        output = image #torch.flatten(image) # retornamos la imagen como salida\n",
    "        return input,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a9f80a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño train_set: 30000\n",
      "Tamaño valid_set: 30000\n"
     ]
    }
   ],
   "source": [
    "# 3.2)\n",
    "# Convertimos FashionMNIST Dataset a CustomDataset\n",
    "train_set_autoencoder = CustomDataset(train_set_orig_autoencoder)\n",
    "valid_set_autoencoder = CustomDataset(valid_set_orig_autoencoder)\n",
    "\n",
    "print(f\"Tamaño train_set: {len(train_set_autoencoder)}\")\n",
    "print(f\"Tamaño valid_set: {len(valid_set_autoencoder)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e78d452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Definir modelo Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"Experimento 1: Autoencoder convolucional básico\"\"\"\n",
    "\n",
    "    def __init__(self, dropout = 0.15):\n",
    "        super().__init__()\n",
    "        # Encoder: (1, 28, 28) -> (32, 14, 14) -> (64, 7, 7)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),  # (1, 28, 28) -> (32, 28, 28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (32, 28, 28) -> (32, 14, 14)\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),  # (32, 14, 14) -> (64, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (64, 14, 14) -> (64, 7, 7)\n",
    "        )\n",
    "\n",
    "        # Decoder: (64, 7, 7) -> (32, 14, 14) -> (1, 28, 28)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=2, stride=2),  # (64, 7, 7) -> (32, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=2, stride=2),  # (32, 14, 14) -> (1, 28, 28)\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49fec747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.15, inplace=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): ConvTranspose2d(32, 1, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Crear instancia de modelo\n",
    "p_dropout = 0.15\n",
    "autoencoder = Autoencoder(dropout=p_dropout).to(device)\n",
    "print(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d7ea4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1)\n",
    "# Definimos la función de entrenamiento\n",
    "def train_loop(dataloader, model, loss_fn, optimizer,verbose=True):\n",
    "    # Activamos la maquinaria de entrenamiento del modelo\n",
    "    model.train()\n",
    "    # Definimos ciertas constantes\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    sum_loss = 0\n",
    "    sum_samples = 0\n",
    "    # Movemos el modelo a la GPU si es que está disponible\n",
    "    model = model.to(device)\n",
    "    #Iteramos sobre lotes (batchs)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        # Copiamos las entradas y salidas al dispositvo de trabajo si es que está disponible\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        batch_size = len(X)\n",
    "        sum_samples += batch_size\n",
    "        # Calculamos la predicción del modelo y la correspondiente función de pérdida\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        # Backpropagamos usando el optimizaor provisto\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Calculamos la pérdida promedio del batch y lo agregamos a una suma correspondiente\n",
    "        sum_loss += loss.item() * batch_size\n",
    "        # Reportamos el progreso\n",
    "        if batch % (num_batches/10) == 0 and verbose:\n",
    "            current = batch*len(X)\n",
    "            avrg_loss = sum_loss/sum_samples\n",
    "            print(f'@train_loop batch={batch:>5d} loss={avrg_loss:>7f} proccesed samples={100*sum_samples/num_samples:>5f}%')\n",
    "    avrg_loss = sum_loss/num_samples\n",
    "    return avrg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dd54495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2)\n",
    "# De manera similar, definimos la función de validación\n",
    "def eval_loop(dataloader,model,loss_fn):\n",
    "  # Desactivamos la maquinaria e entrenamiento del modelo\n",
    "  model.eval()\n",
    "  # Definimos ciertas constantes\n",
    "  num_samples = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  sum_loss = 0\n",
    "  sum_samples = 0\n",
    "  # Movemos el modelo a la GPU si es que está disponible\n",
    "  model = model.to(device)\n",
    "  # Para testear, desactivmos el cálculo de gradientes\n",
    "  with torch.no_grad():\n",
    "    # Iteramos sobre lotes (batches)\n",
    "    for X,y in dataloader:\n",
    "      # Copiamos las entradas y salidas al dispositvo de trabajo si es que está disponible\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "      batch_size = len(X)     # number of samples in the batch\n",
    "      sum_samples += batch_size\n",
    "      # Calculamos las predicciones del modelo\n",
    "      pred = model(X)\n",
    "      loss = loss_fn(pred,y)\n",
    "      # Calculamos la pérdida promedio del batch y lo agregamos a una suma correspondiente\n",
    "      sum_loss += loss.item() * batch_size\n",
    "  # Calculamos la pérdida total y la fracción de clasificaciones correctas y las imprimimos\n",
    "  avrg_loss = sum_loss/sum_samples\n",
    "  #print(f'@eval loop avrg loss={avg loss:>8f}')\n",
    "  return avrg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea03544f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_batches=300\n",
      "num_valid_batches=300\n"
     ]
    }
   ],
   "source": [
    "# 4) Preparar Dataset y DataLoader\n",
    "batch_size = 100\n",
    "train_loader_autoencoder = DataLoader(train_set_autoencoder, batch_size=batch_size, shuffle=True)\n",
    "valid_loader_autoencoder = DataLoader(valid_set_autoencoder, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "num_train_batches = len(train_loader_autoencoder)\n",
    "num_valid_batches = len(valid_loader_autoencoder)\n",
    "print(f'num_train_batches={num_train_batches}')\n",
    "print(f'num_valid_batches={num_valid_batches}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5db03285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Definir loops de entrenamiento y validación\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d51059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.6)\n",
    "# Creamos un optimizador, un Stochastic Gradient Descent o un ADAM\n",
    "learning_rate = 1e-3\n",
    "#optimizer = torch.optim.SGD(model.parameter(),lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(),lr=learning_rate,eps=1e-08,weight_decay=0,amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbe18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.7)\n",
    "# Determinamos en que dispositivo vamos a trabajar, con una CPU o GPU\n",
    "devide = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Pasamos el modelo al dispositivo\n",
    "autoencoder = autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2cdf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=1.424580 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.886824 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.767053 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.723400 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.698660 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.681553 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.669186 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.659497 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.650971 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.644911 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.6402920903762181\n",
      "avg_train_loss.append= 0.5921957776943843\n",
      "avg_valid_loss.append= 0.5917169545094172\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.596690 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.585337 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.590212 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.589900 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.589927 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.589549 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.589808 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.589079 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.589740 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.589691 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5893982374668121\n",
      "avg_train_loss.append= 0.5851837992668152\n",
      "avg_valid_loss.append= 0.5847691222031911\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.583558 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.583875 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.584986 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.583449 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.584311 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.584419 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.584363 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.584043 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.584284 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.584759 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5850558495521545\n",
      "avg_train_loss.append= 0.5822491067647934\n",
      "avg_valid_loss.append= 0.5818461577097574\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.585924 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.581268 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.580966 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.583496 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.583111 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.583099 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.582136 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.582530 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.582254 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.582668 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5829459476470947\n",
      "avg_train_loss.append= 0.5807083994150162\n",
      "avg_valid_loss.append= 0.58031917989254\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.577363 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.581784 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.582112 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.581203 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.580835 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.581630 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.581733 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.581751 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.581838 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.581941 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5816956263780594\n",
      "avg_train_loss.append= 0.5797635424137115\n",
      "avg_valid_loss.append= 0.5793811015288035\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.589075 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.578253 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.579869 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.580897 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.582085 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.582291 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.582054 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.581539 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.581433 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.581014 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5808054641882578\n",
      "avg_train_loss.append= 0.5790577824910482\n",
      "avg_valid_loss.append= 0.5786837899684906\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.580165 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.580168 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.580473 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.581367 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.581003 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.580979 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.580994 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.580587 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.580634 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.580218 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5801217287778855\n",
      "avg_train_loss.append= 0.5785039240121841\n",
      "avg_valid_loss.append= 0.5781373250484466\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.547717 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.574804 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.579509 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.580556 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.580117 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.580803 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.580086 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.579942 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.579571 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.579837 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5795668550332387\n",
      "avg_train_loss.append= 0.5780427197615305\n",
      "avg_valid_loss.append= 0.5776797153552373\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.545928 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.577216 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.578676 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.578539 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.578699 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.578865 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.579442 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.578943 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.579464 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.579504 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5791130419572195\n",
      "avg_train_loss.append= 0.5776290136575699\n",
      "avg_valid_loss.append= 0.5772705123821894\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.557794 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.580015 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.577798 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.577973 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.578546 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.578887 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.579221 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.579235 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.579079 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.578832 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5787210269769033\n",
      "avg_train_loss.append= 0.5772999207178752\n",
      "avg_valid_loss.append= 0.5769470232725143\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.568246 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.576086 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.577956 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.577886 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.578150 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.578394 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.578064 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.577441 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.577941 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.578509 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5784021055698395\n",
      "avg_train_loss.append= 0.5770212312539419\n",
      "avg_valid_loss.append= 0.5766709117094676\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.583371 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.580764 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.577873 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.577142 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.576712 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.576827 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.577085 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.578104 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.578211 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.577914 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5781292871634165\n",
      "avg_train_loss.append= 0.5768239347139994\n",
      "avg_valid_loss.append= 0.5764758342504501\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.569849 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.577127 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575274 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575359 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.576258 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.576349 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.577057 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.578077 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.577824 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.577779 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5778722321987152\n",
      "avg_train_loss.append= 0.576546355287234\n",
      "avg_valid_loss.append= 0.5762006608645122\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.572739 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.579402 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.580038 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.578910 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.577723 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.577723 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.577571 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.577999 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.578111 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.577417 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5776493499676386\n",
      "avg_train_loss.append= 0.5763807173569997\n",
      "avg_valid_loss.append= 0.5760375612974167\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.554764 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.577428 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.574095 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575463 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.576440 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.576326 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.576682 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.577183 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.577392 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.577266 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5774499996503194\n",
      "avg_train_loss.append= 0.576213413476944\n",
      "avg_valid_loss.append= 0.575870482524236\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.536932 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.574870 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.577768 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.576972 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.577475 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.576776 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.576775 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.577335 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.577611 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.577214 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5772748361031215\n",
      "avg_train_loss.append= 0.5761220194896062\n",
      "avg_valid_loss.append= 0.5757813211282095\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.592347 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.576787 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.578125 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.579491 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.577679 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.577322 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.577725 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.577182 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.576466 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.577054 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5771003953615824\n",
      "avg_train_loss.append= 0.5758668788274129\n",
      "avg_valid_loss.append= 0.5755272481838862\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.589279 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.578331 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.577501 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.577607 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.577623 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.577788 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.578338 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.577503 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.577460 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.576941 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5769100687901179\n",
      "avg_train_loss.append= 0.5757140346368154\n",
      "avg_valid_loss.append= 0.5753787797689438\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.595361 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.578992 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.576432 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.577752 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.577985 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.577945 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.577401 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.577543 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.577187 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.577111 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5767426558335622\n",
      "avg_train_loss.append= 0.5755861304203669\n",
      "avg_valid_loss.append= 0.5752511705954869\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.576699 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.573493 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575507 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.574962 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575664 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575555 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575468 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575652 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575407 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.576165 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5765841722488403\n",
      "avg_train_loss.append= 0.5754338711500168\n",
      "avg_valid_loss.append= 0.575100969473521\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.576923 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.572477 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.572802 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.573922 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575171 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575022 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575151 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575977 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.576011 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.576201 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5764148118098577\n",
      "avg_train_loss.append= 0.575298068523407\n",
      "avg_valid_loss.append= 0.5749670020739237\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.582992 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.578238 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.578694 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.576747 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.577057 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.577121 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.576733 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.576782 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.576388 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.576459 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5762904675801596\n",
      "avg_train_loss.append= 0.575201203028361\n",
      "avg_valid_loss.append= 0.5748728209733963\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.552690 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.571361 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575782 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.574116 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.574717 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575572 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575655 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.576176 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575949 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.576150 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5761751238505045\n",
      "avg_train_loss.append= 0.5750758514801662\n",
      "avg_valid_loss.append= 0.574749278028806\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.564097 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.576084 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575627 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.573431 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.573633 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.574275 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.574978 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575101 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575433 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575603 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5760777417818705\n",
      "avg_train_loss.append= 0.5749926970402399\n",
      "avg_valid_loss.append= 0.5746659950415294\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.584264 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.575588 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.574359 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575398 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575153 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575677 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575013 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575060 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575638 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575895 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5759792931874593\n",
      "avg_train_loss.append= 0.5748966886599859\n",
      "avg_valid_loss.append= 0.5745699272553126\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.590015 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.572265 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575743 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575570 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.576128 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.576139 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575860 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575779 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575657 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575294 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5758845168352127\n",
      "avg_train_loss.append= 0.5748209631443024\n",
      "avg_valid_loss.append= 0.5744970144828161\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.585154 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.578386 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.578072 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.578498 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.578712 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.577052 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.577282 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.576975 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.576773 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.576151 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5757979464530945\n",
      "avg_train_loss.append= 0.5747650009393692\n",
      "avg_valid_loss.append= 0.5744401727120082\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.563621 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.576015 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.574678 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.576306 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575143 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575364 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575447 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575357 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575231 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.576065 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5757231485843658\n",
      "avg_train_loss.append= 0.5747126682599386\n",
      "avg_valid_loss.append= 0.5743897287050883\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.586957 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.576702 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.574974 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.576035 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.574827 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.574988 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.574369 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.574577 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.574803 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575475 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5756565324465434\n",
      "avg_train_loss.append= 0.5746079987287521\n",
      "avg_valid_loss.append= 0.5742864392201106\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.560808 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.576853 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.573313 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.574730 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575298 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.576170 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575416 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.576182 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.576430 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575960 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5755876584847768\n",
      "avg_train_loss.append= 0.574590386946996\n",
      "avg_valid_loss.append= 0.5742686718702317\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.570411 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.576453 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575585 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575975 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575747 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.576339 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.576403 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575754 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575584 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575479 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5755353657404582\n",
      "avg_train_loss.append= 0.5745072976748149\n",
      "avg_valid_loss.append= 0.5741879250605901\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.588205 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.572264 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575611 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575054 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.574323 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.573845 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.574638 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575052 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575332 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575599 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5754684368769328\n",
      "avg_train_loss.append= 0.5744441250960032\n",
      "avg_valid_loss.append= 0.5741254436969757\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.551066 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.574590 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.574106 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575264 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.574822 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575319 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.574840 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.574963 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575289 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575535 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5754231544335683\n",
      "avg_train_loss.append= 0.5744220556815466\n",
      "avg_valid_loss.append= 0.5741028352578481\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.582794 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.574716 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575184 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575747 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575709 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575311 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575487 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575679 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575481 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575282 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5753734950224558\n",
      "avg_train_loss.append= 0.5743988124529521\n",
      "avg_valid_loss.append= 0.5740812017520269\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.583322 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.574250 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.576605 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.576067 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575815 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575445 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575216 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575357 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575367 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575396 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5753222658236822\n",
      "avg_train_loss.append= 0.5743244387706121\n",
      "avg_valid_loss.append= 0.5740061648686727\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.607823 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.577814 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.577325 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.578075 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.577131 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.576160 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.576134 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575568 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575578 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575199 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5752835136651993\n",
      "avg_train_loss.append= 0.5742825357119242\n",
      "avg_valid_loss.append= 0.573965611855189\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.566703 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.576826 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575905 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575824 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.576227 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.576213 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.576555 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.576419 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.576026 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575806 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5752396716674169\n",
      "avg_train_loss.append= 0.574282238483429\n",
      "avg_valid_loss.append= 0.5739640017350515\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.591222 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.579503 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.577314 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.576790 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.576170 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575446 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575582 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575703 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575860 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.576065 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5752096851666768\n",
      "avg_train_loss.append= 0.5742280594507854\n",
      "avg_valid_loss.append= 0.5739124691486359\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.574542 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.577968 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575612 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.576869 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.576291 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575476 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575894 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575436 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575144 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.574953 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5751764363050461\n",
      "avg_train_loss.append= 0.5741933188835779\n",
      "avg_valid_loss.append= 0.5738777087132136\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.579045 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.575247 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.573329 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.574158 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.574167 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.574709 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575778 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575879 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575022 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575006 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5751422888040543\n",
      "avg_train_loss.append= 0.5741706315676371\n",
      "avg_valid_loss.append= 0.5738588070869446\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.560327 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.570533 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.572239 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.573405 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575116 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.574988 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.574812 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.574985 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575605 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575131 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5750970844427744\n",
      "avg_train_loss.append= 0.5741722605625789\n",
      "avg_valid_loss.append= 0.5738591233889262\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.574836 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.577638 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.576436 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575275 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.576337 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575918 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575475 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575535 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.574911 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575037 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5750712625185649\n",
      "avg_train_loss.append= 0.5741180930534998\n",
      "avg_valid_loss.append= 0.573806901772817\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.539920 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.569634 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.574189 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575279 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575407 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575929 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.576187 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575694 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575534 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575243 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5750284558534622\n",
      "avg_train_loss.append= 0.5740827506780625\n",
      "avg_valid_loss.append= 0.5737738148371379\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.583820 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.576907 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.576628 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.576217 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.576083 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.576843 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.576174 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575967 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.576238 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575838 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5750070397059123\n",
      "avg_train_loss.append= 0.5740628912051519\n",
      "avg_valid_loss.append= 0.5737525361776352\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.573778 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.576105 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575880 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.576704 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.575578 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.574812 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.574398 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.574873 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575033 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575183 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5749824090798696\n",
      "avg_train_loss.append= 0.574050462047259\n",
      "avg_valid_loss.append= 0.5737407114108404\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.593532 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.575966 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.573460 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.574084 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.573844 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.574158 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.573908 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.574240 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.574875 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575126 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5749566024541855\n",
      "avg_train_loss.append= 0.5740075812737147\n",
      "avg_valid_loss.append= 0.5737007959683736\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.578708 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.572802 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.574188 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.573826 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.573840 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.574048 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.573892 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.574021 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.574675 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.574809 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5749378915627797\n",
      "avg_train_loss.append= 0.5740130581458409\n",
      "avg_valid_loss.append= 0.5737050984303157\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.574787 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.578562 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.575204 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.574387 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.574930 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575010 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575086 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575057 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575006 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.574712 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5749163293838501\n",
      "avg_train_loss.append= 0.5740042652686437\n",
      "avg_valid_loss.append= 0.5736983809868494\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.585581 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.572576 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.572888 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.575165 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.574748 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.574627 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.574423 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.574433 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.574540 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.574537 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5748983758687973\n",
      "avg_train_loss.append= 0.5739733878771464\n",
      "avg_valid_loss.append= 0.5736641325553258\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "@train_loop batch=    0 loss=0.565927 proccesed samples=0.333333%\n",
      "@train_loop batch=   30 loss=0.578291 proccesed samples=10.333333%\n",
      "@train_loop batch=   60 loss=0.577988 proccesed samples=20.333333%\n",
      "@train_loop batch=   90 loss=0.577642 proccesed samples=30.333333%\n",
      "@train_loop batch=  120 loss=0.576620 proccesed samples=40.333333%\n",
      "@train_loop batch=  150 loss=0.575126 proccesed samples=50.333333%\n",
      "@train_loop batch=  180 loss=0.575011 proccesed samples=60.333333%\n",
      "@train_loop batch=  210 loss=0.575540 proccesed samples=70.333333%\n",
      "@train_loop batch=  240 loss=0.575492 proccesed samples=80.333333%\n",
      "@train_loop batch=  270 loss=0.575283 proccesed samples=90.333333%\n",
      "avg_train_loss_incorrecta.append= 0.5748862220843634\n",
      "avg_train_loss.append= 0.5739584279060364\n",
      "avg_valid_loss.append= 0.5736536016066869\n",
      "Done!\n",
      "Checkpoint guardado en: /home/usuario/Documentos/RedesNeuronales/TPFinal/Clasificadora/1_design/autoencoder_fashionmnist.pt\n"
     ]
    }
   ],
   "source": [
    "# 6) Entrenar Autoencoder y guardar parámetros\n",
    "num_epochs = 50\n",
    "list_avg_train_loss_incorrecta = []\n",
    "list_avg_train_loss = []\n",
    "list_avg_valid_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "  print(f'Epoch {epoch+1}\\n-------------------------------')\n",
    "  avg_train_loss_incorrecta = train_loop(train_loader_autoencoder,autoencoder,loss_fn,optimizer)\n",
    "  avg_train_loss = eval_loop(train_loader_autoencoder,autoencoder,loss_fn)\n",
    "  avg_valid_loss = eval_loop(valid_loader_autoencoder,autoencoder,loss_fn)\n",
    "  list_avg_train_loss_incorrecta.append(avg_train_loss_incorrecta)\n",
    "  list_avg_train_loss.append(avg_train_loss)\n",
    "  list_avg_valid_loss.append(avg_valid_loss)\n",
    "  print('avg_train_loss_incorrecta.append=',avg_train_loss_incorrecta)\n",
    "  print('avg_train_loss.append=',avg_train_loss)\n",
    "  print('avg_valid_loss.append=',avg_valid_loss)\n",
    "print('Done!')\n",
    "\n",
    "# Preparar carpeta de salida (elige la ruta donde guardarás el checkpoint)\n",
    "output_dir = \"/home/usuario/Documentos/RedesNeuronales/TPFinal/Clasificadora/1_design\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "checkpoint = {\n",
    "    \"model_state_dict\": autoencoder.state_dict(),\n",
    "    \"encoder_state_dict\": autoencoder.encoder.state_dict(),\n",
    "    \"hyperparams\": {\n",
    "        \"dropout\": p_dropout,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "    },\n",
    "    \"train_loss_incorreta\": list_avg_train_loss_incorrecta,\n",
    "    \"train_loss\": list_avg_train_loss,\n",
    "    \"valid_loss\": list_avg_valid_loss,\n",
    "    \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "checkpoint_path = os.path.join(output_dir, \"autoencoder_fashionmnist.pt\")\n",
    "\n",
    "torch.save(checkpoint, checkpoint_path)\n",
    "print(f\"Checkpoint guardado en: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d664b8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x732ed04a0c80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.10)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "# plt.xlim(-0.1,5.1)\n",
    "# plt.ylim(-0.1,1.1)\n",
    "plt.plot(list(range(1,len(list_avg_train_loss_incorrecta)+1)),list_avg_train_loss_incorrecta,label='Train loss incorrecta',linestyle='-',c='red')\n",
    "plt.plot(list(range(1,len(list_avg_train_loss)+1)),list_avg_train_loss,label='Train loss',linestyle='-',c='green')\n",
    "plt.plot(list(range(1,len(list_avg_valid_loss)+1)),list_avg_valid_loss,label='Valid loss',linestyle='-',c='blue')\n",
    "plt.title('')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a400c",
   "metadata": {},
   "source": [
    "## Cómo cargar el encoder entrenado desde otro notebook (por ejemplo, `train.ipynb`)\n",
    "\n",
    "Ejemplo de uso en otro archivo:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Asegúrate de tener la misma definición de Autoencoder\n",
    "from autoencoder import Autoencoder  # o copia la clase Autoencoder a tu notebook\n",
    "\n",
    "checkpoint_path = \"/home/usuario/Documentos/RedesNeuronales/TPFinal/Clasificadora/1_design/autoencoder_fashionmnist.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "autoencoder = Autoencoder(dropout=checkpoint[\"hyperparams\"][\"dropout\"])\n",
    "autoencoder.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "encoder = autoencoder.encoder\n",
    "\n",
    "# Ejemplo: pasar encoder a tu modelo Clasificadora\n",
    "clasificador = Clasificadora(p=0.2, n1=128, n2=64, encoder=encoder)\n",
    "```\n",
    "\n",
    "De esta forma puedes entrenar el autoencoder aquí y reutilizar sus parámetros en tu notebook de clasificación (`train.ipynb`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
